{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't run the following Cell if you are using local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://{GITHUB_ACCESS_TOKEN}@github.com/AliMohseninejad/ganbert-classifier.git\n",
    "!rm ganbert-classifier/Codes/main.ipynb\n",
    "!cp -r ganbert-classifier/Codes/data/ ./\n",
    "!cp -r ganbert-classifier/Codes/evaluation/ ./\n",
    "!cp -r ganbert-classifier/Codes/model/ ./\n",
    "!cp -r ganbert-classifier/Codes/training/ ./\n",
    "!cp -r ganbert-classifier/Dataset/ ../\n",
    "!cp -r ganbert-classifier/Plots/ ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell only if you are using google colab.\n",
    "The dataset should be available on your google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dataset_path = \"drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell only if you are using Kaggle. The dataset should be first uploaded to Kaggle as the \"subtaskB\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/kaggle/input/subtaskB/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell only if you are using local machine. The dataset should be in the \"Dataset\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from data.data_loader import generate_dataloader\n",
    "from model.bert import get_bert_model, get_tokenizer\n",
    "from model.discriminator import Discriminator\n",
    "from model.generator1 import Generator\n",
    "from training.train import train_vanilla_classier, train_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4\n",
    "val_test_batch_size = 4\n",
    "epochs = 10\n",
    "learning_rate = 5e-5\n",
    "model_name = \"bert-base-cased\"\n",
    "bert_tokenizer, bert_config = get_tokenizer(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../Plots/vanilla-bert/\"):\n",
    "    os.mkdir(path=\"../Plots/vanilla_bert/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unsupervised_ratio in [0.99, 0.95, 0.90, 0.50]:\n",
    "    bert_save_path = f\"../Plots/vanilla-bert/bert_{int(100*(1-unsupervised_ratio))}sup.pth\"\n",
    "    discriminator_save_path = (\n",
    "        f\"../Plots/vanilla-bert/discriminator_{int(100*(1-unsupervised_ratio))}sup.pth\"\n",
    "    )\n",
    "\n",
    "    bert_model, _ = get_bert_model(model_name=model_name)\n",
    "    classifier = Discriminator()\n",
    "\n",
    "    # Get dataloaders\n",
    "    train_dataloader, val_dataloader, test_dataloader = generate_dataloader(\n",
    "        dataset_folder_path=dataset_path,\n",
    "        unsupervised_ratio=unsupervised_ratio,\n",
    "        tokenizer=bert_tokenizer,\n",
    "        train_batch_size=train_batch_size,\n",
    "        valid_batch_size=val_test_batch_size,\n",
    "        test_batch_size=val_test_batch_size,\n",
    "        use_bow_dataset=False,\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    # Define optimizer\n",
    "    model_params = [v for v in bert_model.parameters()] + [\n",
    "        v for v in classifier.parameters()\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(model_params, lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    bert_model, classifier, vanilla_training_results = train_vanilla_classier(\n",
    "        transformer=bert_model,\n",
    "        classifier=classifier,\n",
    "        optimizer=optimizer,\n",
    "        epochs=epochs,\n",
    "        scheduler=None,\n",
    "        train_dataloader=train_dataloader,\n",
    "        validation_dataloader=val_dataloader,\n",
    "        bert_save_path=bert_save_path,\n",
    "        discriminator_save_path=discriminator_save_path,\n",
    "    )\n",
    "\n",
    "    # Test the model\n",
    "\n",
    "    # Visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 4\n",
    "val_test_batch_size = 4\n",
    "epochs = 10\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "model_name = \"bert-base-cased\"\n",
    "bert_tokenizer, bert_config = get_tokenizer(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../Plots/generator1/\"):\n",
    "    os.mkdir(path=\"../Plots/generator1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unsupervised_ratio in [0.99, 0.95, 0.90, 0.50]:\n",
    "    bert_save_path = (\n",
    "        f\"../Plots/generator1/bert_{int(100*(1-unsupervised_ratio))}sup.pth\"\n",
    "    )\n",
    "    discriminator_save_path = (\n",
    "        f\"../Plots/generator1/discriminator_{int(100*(1-unsupervised_ratio))}sup.pth\"\n",
    "    )\n",
    "    generator_save_path = (\n",
    "        f\"../Plots/generator1/generator_{int(100*(1-unsupervised_ratio))}sup.pth\"\n",
    "    )\n",
    "\n",
    "    bert_model, _ = get_bert_model(model_name=model_name)\n",
    "    classifier = Discriminator()\n",
    "    generator = Generator()\n",
    "\n",
    "    # Get dataloaders\n",
    "    train_dataloader, val_dataloader, test_dataloader = generate_dataloader(\n",
    "        dataset_folder_path=dataset_path,\n",
    "        unsupervised_ratio=unsupervised_ratio,\n",
    "        tokenizer=bert_tokenizer,\n",
    "        train_batch_size=train_batch_size,\n",
    "        valid_batch_size=val_test_batch_size,\n",
    "        test_batch_size=val_test_batch_size,\n",
    "        use_bow_dataset=False,\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    # Define optimizers\n",
    "    discriminator_params = [v for v in bert_model.parameters()] + [\n",
    "        v for v in classifier.parameters()\n",
    "    ]\n",
    "    generator_params = [v for v in generator.parameters()]\n",
    "    d_optimizer = torch.optim.AdamW(\n",
    "        discriminator_params, lr=learning_rate_discriminator\n",
    "    )\n",
    "    g_optimizer = torch.optim.AdamW(generator_params, lr=learning_rate_generator)\n",
    "\n",
    "    bert_model, generator, classifier, gan1_training_results = train_gan(\n",
    "        transformer=bert_model,\n",
    "        generator=generator,\n",
    "        discriminator=classifier,\n",
    "        bow_mode=False,\n",
    "        generator_optimizer=g_optimizer,\n",
    "        discriminator_optimizer=d_optimizer,\n",
    "        epochs=epochs,\n",
    "        generator_scheduler=None,\n",
    "        discriminator_scheduler=None,\n",
    "        train_dataloader=train_dataloader,\n",
    "        validation_dataloader=val_dataloader,\n",
    "        bert_save_path=bert_save_path,\n",
    "        discriminator_save_path=discriminator_save_path,\n",
    "        generator_save_path=generator_save_path,\n",
    "    )\n",
    "\n",
    "    # Test the model\n",
    "\n",
    "    # Visualize results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
